{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import joblib\n",
        "\n",
        "# ðŸ”¹ Load dataset\n",
        "df = pd.read_csv(\"/content/cleaned_data.csv\")  # Update with actual dataset filename\n",
        "\n",
        "# ðŸ”¹ Define Features and Target\n",
        "X = df.drop(columns=['item_outlet_sales'])  # Replace 'sales' with your actual target column\n",
        "y = df['item_outlet_sales']\n",
        "\n",
        "# ðŸ”¹ Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# ðŸ”¹ Apply Standard Scaling (Important!)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# ðŸ”¹ Save the scaler for Flask app\n",
        "joblib.dump(scaler, \"models/sc.sav\")\n",
        "\n",
        "# ----------------------------------------\n",
        "# ðŸ”¹ XGBoost Model with Hyperparameter Tuning\n",
        "# ----------------------------------------\n",
        "xgb_model = xgb.XGBRegressor(objective='reg:squarederror')\n",
        "\n",
        "param_grid_xgb = {\n",
        "    'n_estimators': [100, 300],\n",
        "    'learning_rate': [0.01, 0.1],\n",
        "    'max_depth': [3, 5],\n",
        "    'subsample': [0.8, 1]\n",
        "}\n",
        "\n",
        "grid_xgb = GridSearchCV(xgb_model, param_grid_xgb, cv=3, scoring='neg_mean_squared_error', verbose=2, n_jobs=-1)\n",
        "grid_xgb.fit(X_train_scaled, y_train)\n",
        "\n",
        "best_xgb = grid_xgb.best_estimator_\n",
        "print(\"âœ… Best XGBoost Params:\", grid_xgb.best_params_)\n",
        "\n",
        "# ðŸ”¹ Evaluate XGBoost\n",
        "y_pred_xgb = best_xgb.predict(X_test_scaled)\n",
        "print(\"XGBoost RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred_xgb)))\n",
        "\n",
        "# ðŸ”¹ Save XGBoost Model\n",
        "joblib.dump(best_xgb, \"models/xgb_model.pkl\")\n",
        "\n",
        "# ----------------------------------------\n",
        "# ðŸ”¹ LightGBM Model with Hyperparameter Tuning\n",
        "# ----------------------------------------\n",
        "lgb_model = lgb.LGBMRegressor()\n",
        "\n",
        "param_grid_lgb = {\n",
        "    'num_leaves': [31, 50],\n",
        "    'learning_rate': [0.01, 0.1],\n",
        "    'n_estimators': [100, 300]\n",
        "}\n",
        "\n",
        "grid_lgb = GridSearchCV(lgb_model, param_grid_lgb, cv=3, scoring='neg_mean_squared_error', verbose=2, n_jobs=-1)\n",
        "grid_lgb.fit(X_train_scaled, y_train)\n",
        "\n",
        "best_lgb = grid_lgb.best_estimator_\n",
        "print(\"âœ… Best LightGBM Params:\", grid_lgb.best_params_)\n",
        "\n",
        "# ðŸ”¹ Evaluate LightGBM\n",
        "y_pred_lgb = best_lgb.predict(X_test_scaled)\n",
        "print(\"LightGBM RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred_lgb)))\n",
        "\n",
        "# ðŸ”¹ Save LightGBM Model\n",
        "joblib.dump(best_lgb, \"models/lgb_model.pkl\")\n",
        "\n",
        "print(\"ðŸŽ‰ Training complete! Models and scaler saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwJ6d_TqJlk3",
        "outputId": "e25b41a7-1b62-4701-9906-bc55ee84eb72"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
            "âœ… Best XGBoost Params: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'subsample': 1}\n",
            "XGBoost RMSE: 1030.4515288043328\n",
            "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000230 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 783\n",
            "[LightGBM] [Info] Number of data points in the train set: 6818, number of used features: 9\n",
            "[LightGBM] [Info] Start training from score 2202.365232\n",
            "âœ… Best LightGBM Params: {'learning_rate': 0.01, 'n_estimators': 300, 'num_leaves': 31}\n",
            "LightGBM RMSE: 1029.0536208296912\n",
            "ðŸŽ‰ Training complete! Models and scaler saved.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir models"
      ],
      "metadata": {
        "id": "cfgeVvVOJ6CB"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}